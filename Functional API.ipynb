{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870a4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras import Model, regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, BatchNormalization, Dropout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], enable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "WEIGHT_DECAY = 0.001\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45090d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_images = os.getcwd() + \"/train_images/\" + train_df.iloc[:, 0].values\n",
    "test_images = os.getcwd() + \"/test_images/\" + test_df.iloc[:, 0].values\n",
    "\n",
    "train_labels = train_df.iloc[:, 1:].values\n",
    "test_labels = test_df.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d76c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n",
    "\n",
    "    # In older versions you need to set shape in order to avoid error\n",
    "    # on newer (2.3.0+) the following 3 lines can safely be removed\n",
    "    image.set_shape((64, 64, 1))\n",
    "    label[0].set_shape([])\n",
    "    label[1].set_shape([])\n",
    "\n",
    "    labels = {\"first_num\": label[0], \"second_num\": label[1]}\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=len(train_labels))\n",
    "    .map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa269829",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = (\n",
    "    test_dataset.map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f1506",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(64,64,1), name='input_layer')\n",
    "conv1 = Conv2D(32,3, kernel_regularizer = regularizers.l2(WEIGHT_DECAY))(input_layer, name = 'conv1')\n",
    "batchnorm1= BatchNormalization()(conv1)\n",
    "act1 = relu(batchnorm1)\n",
    "maxpool1 = MaxPool2D((2,2))(act1)\n",
    "\n",
    "conv2 = Con2D(64 3, kernel_regularizers = regularizers.l2(WEIGHT_DECAY))\n",
    "batchnorm2 = BatchNormalization()(conv2)\n",
    "act2 = relu(batchnorm2)\n",
    "maxpool2 = MaxPool2D((2,2))(act2)\n",
    "\n",
    "conv3 = Conv2D(128, activation='relu', kernel_regularizers = regularizers.l2(WEIGHT_DECAY))(maxpool2)\n",
    "maxpool3 = MaxPool2D((2,2))(conv3)\n",
    "flatten = Flatten()(maxpool3)\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(128, activation='relu')(dropout)\n",
    "output1 = Dense(10, activation = 'softmax', name='first_num')(dense2)\n",
    "output2 = Dense(10, activation='softmax', name='second_num')(dense2)\n",
    "      \n",
    "model = Model(inputs = [input_layer], outputs = [output1, output2])\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer = tf.keras.optimizers.Adam(lr = 0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d88997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, batch_size = BATCH_SIZE, epochs= EPOCHS, verbose = 2)\n",
    "model.evaluate(test_dataset, batch_size = BATCH_SIZE, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
