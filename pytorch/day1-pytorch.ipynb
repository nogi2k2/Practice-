{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euxb2Og5nIaX"
      },
      "source": [
        "**Day - 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67YhQ54EElI6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ1ywu0qm-8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4efd386-5c8d-4190-ae9d-7854f7b96b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Aug 26 17:40:27 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igrRr-9Lm_CH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8406d9ad-cf57-43d1-da8c-877c42c82ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1 2 2 3\n",
            "torch.Size([]) torch.Size([2]) torch.Size([1, 2]) torch.Size([2, 2]) torch.Size([1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.tensor(7)\n",
        "tensor2 = torch.tensor([1,2])\n",
        "tensor3 = torch.tensor([[1,2]])\n",
        "tensor4 = torch.tensor([[4,5],[6,7]])\n",
        "tensor5 = torch.tensor([[[1,2],[3,4]]])\n",
        "\n",
        "print(tensor1.ndim,tensor2.ndim,tensor3.ndim,tensor4.ndim,tensor5.ndim)\n",
        "print(tensor1.shape,tensor2.shape,tensor3.shape,tensor4.shape,tensor5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhyUQuJum_Ju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2ec7c5-78ff-429b-9ccc-76401d2c01db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 torch.Size([1, 3, 3])\n",
            "tensor([[[0.7174, 0.6653, 0.7665],\n",
            "         [0.1527, 0.9405, 0.6546],\n",
            "         [0.1113, 0.4606, 0.1823]]])\n"
          ]
        }
      ],
      "source": [
        "random_tensor = torch.rand((1,3,3))\n",
        "print(random_tensor.ndim, random_tensor.shape)\n",
        "print(random_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LEQudvxm_QL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6acad2f5-1195-4ffc-91ee-7a9cbc6bdf3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 torch.Size([3, 3]) torch.float32 cpu\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "2 torch.Size([3, 3]) torch.float32 cpu False\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "zeros = torch.zeros(3,3)\n",
        "print(zeros.ndim, zeros.shape, zeros.dtype, zeros.device)\n",
        "print(zeros)\n",
        "\n",
        "ones = torch.ones(3,3)\n",
        "print(ones.ndim, ones.shape, ones.dtype, ones.device, ones.requires_grad)\n",
        "print(ones)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_range = torch.range(1,5,0.1)\n",
        "tensor_arange = torch.arange(2,6,0.5)\n",
        "print(tensor_range.ndim, tensor_range.shape)\n",
        "print(tensor_range,\"\\n\")\n",
        "print(tensor_arange.ndim, tensor_arange.shape)\n",
        "print(tensor_arange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBbLoJNG0rzS",
        "outputId": "79263a37-3223-4bc7-9a8d-228c119b92f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 torch.Size([41])\n",
            "tensor([1.0000, 1.1000, 1.2000, 1.3000, 1.4000, 1.5000, 1.6000, 1.7000, 1.8000,\n",
            "        1.9000, 2.0000, 2.1000, 2.2000, 2.3000, 2.4000, 2.5000, 2.6000, 2.7000,\n",
            "        2.8000, 2.9000, 3.0000, 3.1000, 3.2000, 3.3000, 3.4000, 3.5000, 3.6000,\n",
            "        3.7000, 3.8000, 3.9000, 4.0000, 4.1000, 4.2000, 4.3000, 4.4000, 4.5000,\n",
            "        4.6000, 4.7000, 4.8000, 4.9000, 5.0000]) \n",
            "\n",
            "1 torch.Size([8])\n",
            "tensor([2.0000, 2.5000, 3.0000, 3.5000, 4.0000, 4.5000, 5.0000, 5.5000])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-5d044ec82c3b>:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  tensor_range = torch.range(1,5,0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tens_wo_shape = torch.zeros_like(tensor_range)\n",
        "tens_wo_shape_arange = torch.ones_like(tensor_arange)\n",
        "print(tensor_range.shape, tens_wo_shape.shape,\"\\n\")\n",
        "print(tensor_arange.shape, tens_wo_shape_arange.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l5jpNBv0snH",
        "outputId": "5e8cef81-39fb-4a84-e739-eee66c1a1676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([41]) torch.Size([41]) \n",
            "\n",
            "torch.Size([8]) torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensor 1 datatype is: {tensor1.dtype}\")\n",
        "tensor1 = tensor1.type(torch.int8)\n",
        "print(f\"Dtype after change is: {tensor1.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBs7ZEK_0std",
        "outputId": "1850d406-3f01-4919-bb68-7b4d305a26e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor 1 datatype is: torch.int64\n",
            "Dtype after change is: torch.int8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.max(tensor1))\n",
        "print(torch.min(tensor1))\n",
        "print(torch.mean(tensor_range))\n",
        "print(torch.sum(tensor1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cQvAxTq0szv",
        "outputId": "2933fd0e-9fc2-4d03-caad-5dcd25c21f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7, dtype=torch.int8)\n",
            "tensor(7, dtype=torch.int8)\n",
            "tensor(3.)\n",
            "tensor(7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensor range is on device: {tensor_range.device}\\nAnd the type is: {type(tensor_range)}\")\n",
        "print(f\"Now the device is: {tensor_range.to('cuda').device}\")\n",
        "print(f\"Putting it back on cpu: {tensor_range.cpu().device}\")\n",
        "print(f\"Converting to a numpy ndarray: {type(tensor_range.numpy())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTeBOgKq0s7s",
        "outputId": "cbeb19dc-0bfd-49c9-aa9b-c7bd5f358890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor range is on device: cpu\n",
            "And the type is: <class 'torch.Tensor'>\n",
            "Now the device is: cuda:0\n",
            "Putting it back on cpu: cpu\n",
            "Converting to a numpy ndarray: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Xkpi7yT3diK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXGNwTI93dnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hvmRJ3Z63dtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xjmv575j7s36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LN4kL6NT7s9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_bZdYnvx7tWJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}