{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euxb2Og5nIaX"
      },
      "source": [
        "**Day - 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67YhQ54EElI6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ1ywu0qm-8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abbc8c4-588b-45b3-dd63-de215c877fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 27 17:50:39 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igrRr-9Lm_CH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1daa0a6-307f-4203-8ca2-113c65a7a450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1 2 2 3\n",
            "torch.Size([]) torch.Size([2]) torch.Size([1, 2]) torch.Size([2, 2]) torch.Size([1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.tensor(7)\n",
        "tensor2 = torch.tensor([1,2])\n",
        "tensor3 = torch.tensor([[1,2]])\n",
        "tensor4 = torch.tensor([[4,5],[6,7]])\n",
        "tensor5 = torch.tensor([[[1,2],[3,4]]])\n",
        "\n",
        "print(tensor1.ndim,tensor2.ndim,tensor3.ndim,tensor4.ndim,tensor5.ndim)\n",
        "print(tensor1.shape,tensor2.shape,tensor3.shape,tensor4.shape,tensor5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhyUQuJum_Ju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820b7fd0-40fc-4dfa-ea28-fc751905d8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 torch.Size([1, 3, 3])\n",
            "tensor([[[0.6487, 0.9613, 0.7772],\n",
            "         [0.9857, 0.9756, 0.8242],\n",
            "         [0.6960, 0.5135, 0.3615]]])\n"
          ]
        }
      ],
      "source": [
        "random_tensor = torch.rand((1,3,3))\n",
        "print(random_tensor.ndim, random_tensor.shape)\n",
        "print(random_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LEQudvxm_QL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b59b5f7-ba9b-4122-86fc-b182b9fbb5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 torch.Size([3, 3]) torch.float32 cpu\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "2 torch.Size([3, 3]) torch.float32 cpu False\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "zeros = torch.zeros(3,3)\n",
        "print(zeros.ndim, zeros.shape, zeros.dtype, zeros.device)\n",
        "print(zeros)\n",
        "\n",
        "ones = torch.ones(3,3)\n",
        "print(ones.ndim, ones.shape, ones.dtype, ones.device, ones.requires_grad)\n",
        "print(ones)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_range = torch.range(1,5,0.1)\n",
        "tensor_arange = torch.arange(2,6,0.5)\n",
        "print(tensor_range.ndim, tensor_range.shape)\n",
        "print(tensor_range,\"\\n\")\n",
        "print(tensor_arange.ndim, tensor_arange.shape)\n",
        "print(tensor_arange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBbLoJNG0rzS",
        "outputId": "9394d992-fc76-4cf3-853b-464ea3464a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 torch.Size([41])\n",
            "tensor([1.0000, 1.1000, 1.2000, 1.3000, 1.4000, 1.5000, 1.6000, 1.7000, 1.8000,\n",
            "        1.9000, 2.0000, 2.1000, 2.2000, 2.3000, 2.4000, 2.5000, 2.6000, 2.7000,\n",
            "        2.8000, 2.9000, 3.0000, 3.1000, 3.2000, 3.3000, 3.4000, 3.5000, 3.6000,\n",
            "        3.7000, 3.8000, 3.9000, 4.0000, 4.1000, 4.2000, 4.3000, 4.4000, 4.5000,\n",
            "        4.6000, 4.7000, 4.8000, 4.9000, 5.0000]) \n",
            "\n",
            "1 torch.Size([8])\n",
            "tensor([2.0000, 2.5000, 3.0000, 3.5000, 4.0000, 4.5000, 5.0000, 5.5000])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-5d044ec82c3b>:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  tensor_range = torch.range(1,5,0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tens_wo_shape = torch.zeros_like(tensor_range)\n",
        "tens_wo_shape_arange = torch.ones_like(tensor_arange)\n",
        "print(tensor_range.shape, tens_wo_shape.shape,\"\\n\")\n",
        "print(tensor_arange.shape, tens_wo_shape_arange.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l5jpNBv0snH",
        "outputId": "3c3fd3ba-fdb0-4e07-9a76-b665643719f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([41]) torch.Size([41]) \n",
            "\n",
            "torch.Size([8]) torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensor 1 datatype is: {tensor1.dtype}\")\n",
        "tensor1 = tensor1.type(torch.int8)\n",
        "print(f\"Dtype after change is: {tensor1.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBs7ZEK_0std",
        "outputId": "84579278-83f8-4c4d-f702-cb9d2aec84bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor 1 datatype is: torch.int64\n",
            "Dtype after change is: torch.int8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.max(tensor1))\n",
        "print(torch.min(tensor1))\n",
        "print(torch.mean(tensor_range))\n",
        "print(torch.sum(tensor1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cQvAxTq0szv",
        "outputId": "c33023a2-03fb-46f2-e4eb-ee52d53f04db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7, dtype=torch.int8)\n",
            "tensor(7, dtype=torch.int8)\n",
            "tensor(3.)\n",
            "tensor(7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tensor range is on device: {tensor_range.device}\\nAnd the type is: {type(tensor_range)}\")\n",
        "print(f\"Now the device is: {tensor_range.to('cuda').device}\")\n",
        "print(f\"Putting it back on cpu: {tensor_range.cpu().device}\")\n",
        "print(f\"Converting to a numpy ndarray: {type(tensor_range.numpy())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTeBOgKq0s7s",
        "outputId": "7cc363fe-7889-4a83-da1d-10e845cc7f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor range is on device: cpu\n",
            "And the type is: <class 'torch.Tensor'>\n",
            "Now the device is: cuda:0\n",
            "Putting it back on cpu: cpu\n",
            "Converting to a numpy ndarray: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Day-2**"
      ],
      "metadata": {
        "id": "Dy3MapTtT_S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "matmul1 = torch.ones((3,2))\n",
        "matmul2 = torch.rand((3,2))"
      ],
      "metadata": {
        "id": "2Xkpi7yT3diK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"When we try to multiply incompatible shapes: {matmul1 @ matmul2}\")"
      ],
      "metadata": {
        "id": "FXGNwTI93dnC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "62141322-504b-4a80-ab20-6efd8065116e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-06382a40ace5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"When we try to multiply incompatible shapes: {matmul1 @ matmul2}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"When we multiply compatible shapes: {matmul1 @ matmul2.T}\")"
      ],
      "metadata": {
        "id": "hvmRJ3Z63dtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8608f4-ef5a-4343-a394-dd7eae2fa144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When we multiply compatible shapes: tensor([[0.5818, 0.8149, 1.1182],\n",
            "        [0.5818, 0.8149, 1.1182],\n",
            "        [0.5818, 0.8149, 1.1182]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random1 = torch.arange(0,100,10).type(torch.float32)\n",
        "random2 = torch.arange(1,100,11).type(torch.float32)\n",
        "\n",
        "print(\"For the first tensor:\\n\",random1.shape,random1.dtype,random1.device,random1.requires_grad)\n",
        "print(f\"Max: {torch.max(random1)}\\nMin: {torch.min(random1)}\\nMean: {torch.mean(random1)}\\nSum: {torch.sum(random1)}\")\n",
        "\n",
        "print(\"Properties of second tensor:\\n\",random2.shape,random2.dtype,random2.device,random2.requires_grad)\n",
        "print(f\"Max: {torch.max(random2)}\\nMin: {torch.min(random2)}\\nMean: {torch.mean(random2)}\\nSum: {torch.sum(random2)}\")"
      ],
      "metadata": {
        "id": "Xjmv575j7s36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d090bf-7f37-4ceb-9b9b-20d8b6ab8dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the first tensor:\n",
            " torch.Size([10]) torch.float32 cpu False\n",
            "Max: 90.0\n",
            "Min: 0.0\n",
            "Mean: 45.0\n",
            "Sum: 450.0\n",
            "Properties of second tensor:\n",
            " torch.Size([9]) torch.float32 cpu False\n",
            "Max: 89.0\n",
            "Min: 1.0\n",
            "Mean: 45.0\n",
            "Sum: 405.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First tensor argmax: {torch.argmax(random1)}\\nFirst tensor argmin {torch.argmin(random1)}\")\n",
        "print(f\"Second tensor argmax: {torch.argmax(random2)}\\nSecond tensor argmin: {torch.argmin(random2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ-XHRPX_xyI",
        "outputId": "fa6741f0-8514-4bb7-8130-55bd74ca9a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First tensor argmax: 9\n",
            "First tensor argmin 0\n",
            "Second tensor argmax: 8\n",
            "Second tensor argmin: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random3 = torch.rand(3,4).type(torch.float32)\n",
        "print(random3.shape,random3.ndim)\n",
        "random3_changed = random3.resize(2,6)\n",
        "print(random3_changed.shape, random3.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LGtaMum_x3X",
        "outputId": "764f5f8a-4bfa-4f39-f448-98fb1133c2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4]) 2\n",
            "torch.Size([2, 6]) 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Using view: {random3_changed.view(3,4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKt79rGv_yok",
        "outputId": "533e5ed2-bd53-4195-ef94-cd53de1728c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using view: tensor([[0.8487, 0.5354, 0.9941, 0.3809],\n",
            "        [0.9362, 0.4601, 0.9022, 0.8033],\n",
            "        [0.6131, 0.8383, 0.6299, 0.0833]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random4 = torch.rand((1,4))\n",
        "stacked_vert = torch.stack([random4,random4],dim=1)\n",
        "print(f\"Stacked vertically: {stacked_vert}\\ndim: {stacked_vert.ndim}\\nshape: {stacked_vert.shape}\")\n",
        "\n",
        "stacked_hori = torch.stack([random4,random4],dim=0)\n",
        "print(f\"Stacked vertically: {stacked_hori}\\ndim: {stacked_hori.ndim}\\nshape: {stacked_hori.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW7Sn82B_ys6",
        "outputId": "e0fc5d8e-82e7-4366-e78a-8e6594c1ffab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacked vertically: tensor([[[0.4505, 0.2481, 0.4784, 0.2379],\n",
            "         [0.4505, 0.2481, 0.4784, 0.2379]]])\n",
            "dim: 3\n",
            "shape: torch.Size([1, 2, 4])\n",
            "Stacked vertically: tensor([[[0.4505, 0.2481, 0.4784, 0.2379]],\n",
            "\n",
            "        [[0.4505, 0.2481, 0.4784, 0.2379]]])\n",
            "dim: 3\n",
            "shape: torch.Size([2, 1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Squeezing stacked verticaly: {stacked_vert.squeeze().shape}\")\n",
        "print(f\"Unsqueezing stacked horizontally: {stacked_hori.unsqueeze(dim=1).shape}\")"
      ],
      "metadata": {
        "id": "LN4kL6NT7s9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f809a85-62fd-4160-d3cf-02bc2bdb699d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squeezing stacked verticaly: torch.Size([2, 4])\n",
            "Unsqueezing stacked horizontally: torch.Size([2, 1, 1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original: {stacked_hori.shape}\\nTensor: {stacked_hori}\")\n",
        "permuted = stacked_hori.permute(0,2,1)\n",
        "print(f\"Permuted: {permuted.shape}\\nPermuted tensor: {permuted}\")\n",
        "print(f\"Original: {stacked_hori}\")"
      ],
      "metadata": {
        "id": "_bZdYnvx7tWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ae6bfb8-0dcb-4532-8f6b-7929eeaf863b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: torch.Size([2, 1, 4])\n",
            "Tensor: tensor([[[0.4505, 0.2481, 0.4784, 0.2379]],\n",
            "\n",
            "        [[0.4505, 0.2481, 0.4784, 0.2379]]])\n",
            "Permuted: torch.Size([2, 4, 1])\n",
            "Permuted tensor: tensor([[[0.4505],\n",
            "         [0.2481],\n",
            "         [0.4784],\n",
            "         [0.2379]],\n",
            "\n",
            "        [[0.4505],\n",
            "         [0.2481],\n",
            "         [0.4784],\n",
            "         [0.2379]]])\n",
            "Original: tensor([[[0.4505, 0.2481, 0.4784, 0.2379]],\n",
            "\n",
            "        [[0.4505, 0.2481, 0.4784, 0.2379]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.arange(1,100,1)\n",
        "print(type(np_array))\n",
        "tens = torch.from_numpy(np_array).type(torch.float32)\n",
        "print(type(tens))\n",
        "print(tens.device)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(tens.to(device).device)\n",
        "print(f\"Dtype of tensor: {tens.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKES61qpE3sy",
        "outputId": "2f57806e-cd07-4852-e55a-b612d76a8857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'>\n",
            "cpu\n",
            "cuda:0\n",
            "Dtype of tensor: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.manual_seed(42)\n",
        "weights = 0.7\n",
        "bias = 0.3\n",
        "X=torch.arange(0,1,0.02).unsqueeze(dim=1)\n",
        "y = weights*X+bias\n",
        "print(X.shape, X.dtype, X.device)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aixNU5CZE4Qx",
        "outputId": "0992c22f-308d-417c-b7e9-d8f0c9b83945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 1]) torch.float32 cpu\n",
            "tensor([[0.0000],\n",
            "        [0.0200],\n",
            "        [0.0400],\n",
            "        [0.0600],\n",
            "        [0.0800],\n",
            "        [0.1000],\n",
            "        [0.1200],\n",
            "        [0.1400],\n",
            "        [0.1600],\n",
            "        [0.1800],\n",
            "        [0.2000],\n",
            "        [0.2200],\n",
            "        [0.2400],\n",
            "        [0.2600],\n",
            "        [0.2800],\n",
            "        [0.3000],\n",
            "        [0.3200],\n",
            "        [0.3400],\n",
            "        [0.3600],\n",
            "        [0.3800],\n",
            "        [0.4000],\n",
            "        [0.4200],\n",
            "        [0.4400],\n",
            "        [0.4600],\n",
            "        [0.4800],\n",
            "        [0.5000],\n",
            "        [0.5200],\n",
            "        [0.5400],\n",
            "        [0.5600],\n",
            "        [0.5800],\n",
            "        [0.6000],\n",
            "        [0.6200],\n",
            "        [0.6400],\n",
            "        [0.6600],\n",
            "        [0.6800],\n",
            "        [0.7000],\n",
            "        [0.7200],\n",
            "        [0.7400],\n",
            "        [0.7600],\n",
            "        [0.7800],\n",
            "        [0.8000],\n",
            "        [0.8200],\n",
            "        [0.8400],\n",
            "        [0.8600],\n",
            "        [0.8800],\n",
            "        [0.9000],\n",
            "        [0.9200],\n",
            "        [0.9400],\n",
            "        [0.9600],\n",
            "        [0.9800]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = X[:int(0.8*len(X)),0]\n",
        "train_y = y[:int(0.8*len(X)),0]\n",
        "\n",
        "val_x = X[int(0.8*len(X)):50,0]\n",
        "val_y = y[int(0.8*len(X)):50,0]\n",
        "print(train_x, '\\n', val_x)\n",
        "print(len(train_x),len(train_y), '\\n', len(val_x),len(val_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcDrk-1tE4V9",
        "outputId": "661eb796-c5c6-42a1-832f-ff2b97632828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.0200, 0.0400, 0.0600, 0.0800, 0.1000, 0.1200, 0.1400, 0.1600,\n",
            "        0.1800, 0.2000, 0.2200, 0.2400, 0.2600, 0.2800, 0.3000, 0.3200, 0.3400,\n",
            "        0.3600, 0.3800, 0.4000, 0.4200, 0.4400, 0.4600, 0.4800, 0.5000, 0.5200,\n",
            "        0.5400, 0.5600, 0.5800, 0.6000, 0.6200, 0.6400, 0.6600, 0.6800, 0.7000,\n",
            "        0.7200, 0.7400, 0.7600, 0.7800]) \n",
            " tensor([0.8000, 0.8200, 0.8400, 0.8600, 0.8800, 0.9000, 0.9200, 0.9400, 0.9600,\n",
            "        0.9800])\n",
            "40 40 \n",
            " 10 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    # self.linear1 = nn.Linear(inp, hidden1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    z = self.weights*x+self.bias\n",
        "    return z"
      ],
      "metadata": {
        "id": "FeegGxvCE4aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regressor = model()"
      ],
      "metadata": {
        "id": "dSIPRjLxPw_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Day-3**"
      ],
      "metadata": {
        "id": "oiMINTvB6AR-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1jR6PDwEPxLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01Q4vacoE4ed"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}